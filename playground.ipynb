{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qvclVKYqnJ2"
      },
      "source": [
        "# Derin Ã–ÄŸrenmenin Temelleri -  Oyun AlanÄ±"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdjM-C5zqnJ3"
      },
      "source": [
        "ğŸ§  Derin Ã–ÄŸrenme modÃ¼lÃ¼ne hoÅŸ geldiniz!\n",
        "\n",
        "ğŸ¯ Bu gÃ¶revde iki hedefimiz var:\n",
        "1. Sinir aÄŸlarÄ±nÄ±n gÃ¶rsel bir temsilini elde etmek.\n",
        "2. Sinir aÄŸlarÄ±nÄ±n ne yaptÄ±ÄŸÄ±nÄ± daha iyi anlamak.\n",
        "\n",
        "ğŸ‘‰ ***[Tensorflow Playground](https://playground.tensorflow.org/)*** kullanacaÄŸÄ±z.\n",
        "\n",
        "_(Bu ilk gÃ¶rev Ã§ok fazla kodlama gerektirmiyor_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgC6TM9uqnJ4"
      },
      "source": [
        "## Derin Ã–ÄŸrenmede SÄ±nÄ±flandÄ±rma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzKCk0sHqnJ4"
      },
      "source": [
        "### (1) Veriler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKX5PTyWqnJ4"
      },
      "source": [
        "â“ [Oyun AlanÄ±](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=2& seed=0.23545&showTestData=false&discretize=false&percTrainData=70&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false& problem=classification&initZero=false&hideText=false&regularization_hide=true&showTestData_hide=false&stepButton_hide=false&activation_hide=false&problem_hide=false&batchSize_hide=true&dataset_hide=false&resetButton_hide=false&discretize_hide=false&playButton_hide=false& learningRate_hide=true&regularizationRate_hide=true&percTrainData_hide=false&numHiddenLayers_hide=false) ve aÅŸaÄŸÄ±daki veri tÃ¼rÃ¼nÃ¼ seÃ§in â“\n",
        "\n",
        "- Bir sÄ±nÄ±flandÄ±rma problemi\n",
        "- Daire veri kÃ¼mesi (<span style=\"color:blue\">mavi noktalar</span> iÃ§inde <span style=\"color:orange\">turuncu noktalar</span>)\n",
        "- EÄŸitim ve test verilerinin oranÄ±: $ 70 \\% $\n",
        "- GÃ¼rÃ¼ltÃ¼ yok ($ = 0$)\n",
        "- Test verilerini gÃ¶sterme (saÄŸ panel)\n",
        "- Ã‡Ä±ktÄ±yÄ± ayrÄ±ÅŸtÄ±rma\n",
        "- Aktivasyon fonksiyonu: ***ReLU***\n",
        "\n",
        "<details>\n",
        "    <summary><i> Neden Relu? </i></summary>\n",
        "        \n",
        "ğŸ’¡ Genel olarak, varsayÄ±lan olarak deneyin. BirÃ§ok problem iÃ§in daha iyi sonuÃ§ veriyor gibi gÃ¶rÃ¼nÃ¼yor!\n",
        "    \n",
        "_Not: Playground, **tÃ¼m** **gizli** katmanlar iÃ§in kullanÄ±lan **tek** bir aktivasyon fonksiyonu seÃ§menize izin verir_\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpMl_RH4qnJ5"
      },
      "source": [
        "### (2) Ã–zellikler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmab8pVkqnJ5"
      },
      "source": [
        "â“ <u>Ã–zelliklerle ilgili sorular</u> â“\n",
        "\n",
        "1. YalnÄ±zca $X_1$ ve $X_2$ Ã¶zelliklerini seÃ§in (_gerekirse diÄŸer Ã¶zelliklerin seÃ§imini kaldÄ±rÄ±n_).\n",
        "2. $X_1^{2}$, $X_2^{2}$, $X_1 X_2$, $sin(X_1)$ ve $sin(X_2)$ gibi diÄŸer deÄŸiÅŸkenleri kullanÄ±yorsanÄ±z, bunlar hangi klasik Makine Ã–ÄŸrenimi iÅŸlemine karÅŸÄ±lÄ±k gelir?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "2lM12tJIqnJ5"
      },
      "source": [
        "> 58"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9a6i6V3qnJ5"
      },
      "source": [
        "<details>\n",
        "    <summary><i>Cevap</i></summary>\n",
        "\n",
        "* BunlarÄ± dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼ÄŸÃ¼nÃ¼z bir tÃ¼r ***Ã¶zellik mÃ¼hendisliÄŸi*** ile ilgilidir.\n",
        "    * <i>Ã–rnekler: Ã§arpma, sinÃ¼s, karesi, ...</i>\n",
        "* Burada, bu alÄ±ÅŸtÄ±rmada ve yarÄ±n da, yalnÄ±zca ham girdi Ã¶zellikleri $X_1$ ve $X_2$ kullanacaÄŸÄ±z.\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnxElnTAqnJ5"
      },
      "source": [
        "### (3) ***Playground***'da Sinir AÄŸÄ± OluÅŸturma ve Uyarlama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxGvMIs1qnJ5"
      },
      "source": [
        "â“ <u>Sinir AÄŸlarÄ± HakkÄ±nda Sorular</u> â“\n",
        "\n",
        "* ğŸ§  AÅŸaÄŸÄ±daki mimariye sahip bir model oluÅŸturun:\n",
        "- Ã¼Ã§ gizli katman\n",
        "- ilk gizli katmanda 5 nÃ¶ron\n",
        "- ikinci gizli katmanda 4 nÃ¶ron\n",
        "- son gizli katmanda 3 nÃ¶ron\n",
        "- ***Playground***'da Ã§Ä±ktÄ± katmanÄ± gÃ¶sterilmez:\n",
        "        - Ä°kili sÄ±nÄ±flandÄ±rma gÃ¶revi iÃ§in Playground, tanh (hiperbolik tanjant) fonksiyonu $ \\large \\phi(z) = \\frac{sinh(z)}{cosh(z)} = \\frac{e^z - e^{-z}}{e^z + e^{-z}} $ ile etkinleÅŸtirilen 1 nÃ¶ronlu yoÄŸun bir katman kullanÄ±r.\n",
        "        - Bu tanh fonksiyonu -1 ile 1 arasÄ±ndaki deÄŸerleri Ã§Ä±karÄ±r ve Playground'da gÃ¼zel bir ÅŸekilde gÃ¶rselleÅŸtirilir.\n",
        "- Ancak, pratikte, ikili sÄ±nÄ±flandÄ±rma iÃ§in, 0 ile 1 arasÄ±ndaki Ã§Ä±ktÄ±larÄ± olan sigmoid fonksiyonunu kullanmaya geri dÃ¶neceÄŸiz. Lojistik Regresyonu hatÄ±rlayÄ±n!\n",
        "        - Matematik severler iÃ§in: sigmoid ve tanh aynÄ± ÅŸekle sahiptir: birbirlerinin sadece kaydÄ±rÄ±lmÄ±ÅŸ ve uzatÄ±lmÄ±ÅŸ versiyonlarÄ±dÄ±r.\n",
        "\n",
        "* ğŸ’ª ***UyarlayÄ±n ve kayÄ±p fonksiyonu stabilize olduÄŸunda yinelemeleri durdurun.***\n",
        "\n",
        "* ğŸ‘€ Dikkatlice gÃ¶zlemleyin:\n",
        "- Tek tek nÃ¶ronlara bakÄ±n ve her nÃ¶ronun _.fit()_ sÄ±rasÄ±nda neye uzmanlaÅŸtÄ±ÄŸÄ±nÄ± anlamaya Ã§alÄ±ÅŸÄ±n.\n",
        "- SonuÃ§larÄ±nÄ±zÄ±n genel ÅŸekli hakkÄ±nda ne dÃ¼ÅŸÃ¼nÃ¼yorsunuz? KarÅŸÄ±laÅŸtÄ±rmak iÃ§in farklÄ± aktivasyon fonksiyonlarÄ±yla sinir aÄŸÄ±nÄ± yeniden Ã§alÄ±ÅŸtÄ±rÄ±n. â€œLineerâ€ ile Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlayabilir misiniz?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6glk25bhqnJ6"
      },
      "source": [
        "<details>\n",
        "    <summary>Cevap: aktivasyon fonksiyonlarÄ± hakkÄ±nda bazÄ± bilgiler</summary>\n",
        "\n",
        "- ReLu parÃ§a parÃ§a doÄŸrusal olduÄŸu iÃ§in sonuÃ§lar altÄ±gen gibi gÃ¶rÃ¼nebilir!\n",
        "- DoÄŸrusal olarak ayrÄ±ÅŸtÄ±rÄ±lamayan bir problem, **Linear** gibi doÄŸrusal bir aktivasyonla uyumlu hale getirilemez\n",
        "- ÅaÅŸÄ±rtÄ±cÄ± bir ÅŸekilde, **ReLu** (veya **LeakyReLu**) gibi parÃ§a parÃ§a doÄŸrusal bir aktivasyon fonksiyonu, bu doÄŸrusal olarak ayrÄ±ÅŸtÄ±rÄ±lamayan problemi iyi bir ÅŸekilde uyumlu hale getirir (her zaman doÄŸru olmasa da)\n",
        "- `tanh` aktivasyonu, â€œdaha yumuÅŸakâ€ bir karar sÄ±nÄ±rÄ± saÄŸlar\n",
        "- **Sigmoid** burada iyi Ã§alÄ±ÅŸmÄ±yor gibi gÃ¶rÃ¼nÃ¼yor (yani, etkili bir ÅŸekilde sÄ±nÄ±flandÄ±rma yapabilmesi iÃ§in __Ã§ok__ fazla dÃ¶nem gerekiyor)\n",
        "\n",
        "ğŸ§‘ğŸ»â€ğŸ« Her zaman ReLu ile baÅŸlayÄ±n, bu gÃ¼venli bir seÃ§imdir ğŸ§‘ğŸ»â€ğŸ«!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Ai_n2tqnJ6"
      },
      "source": [
        "### (4) ***Tensorflow.Keras***'da Sinir AÄŸÄ± OluÅŸturma ve Uyarlama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9F60nQxqnJ6"
      },
      "source": [
        "ğŸ‘‡ Tensorflow'un Keras'Ä±nda sizin iÃ§in aynÄ± modeli yazdÄ±k - en azÄ±ndan mimariyi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MR-vjwiKqnJ6"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential, Input, layers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=(2,))) # 2 Ã¶zellikli giriÅŸ katmanÄ±\n",
        "\n",
        "model.add(layers.Dense(5, activation='relu')) # 5 nÃ¶ronlu 1. gizli katman\n",
        "model.add(layers.Dense(4, activation='relu')) # 4 nÃ¶ronlu 2. gizli katman\n",
        "model.add(layers.Dense(3, activation='relu')) # 3 nÃ¶ronlu 3. gizli katman\n",
        "\n",
        "model.add(layers.Dense(1, activation='sigmoid')) # Ait olma olasÄ±lÄ±ÄŸÄ±nÄ± Ã§Ä±ktÄ± olarak veren Ã§Ä±ktÄ± katmanÄ±\n",
        "                                                 # â€œbaÅŸarÄ±â€ sÄ±nÄ±fÄ±na"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l6sppzuqnJ6"
      },
      "source": [
        "<details>\n",
        "  <summary><i>Bir Sinir AÄŸÄ± (Neural Network) kodu hakkÄ±nda neyi anlamalÄ±yÄ±z?</i> ğŸ‘†</summary>\n",
        "\n",
        "- <u>Ä°lk Gizli Katman (a.k.a. ***Girdi KatmanÄ± / Input Layer***)</u>:\n",
        "  - Sinir aÄŸÄ±na giren her veri noktasÄ± iki Ã¶zelliÄŸe sahiptir:  \n",
        "    \\( X = \\begin{bmatrix} X_{1} \\\\ X_{2} \\end{bmatrix} \\)\n",
        "  - Sinir aÄŸÄ±na ***girdi Ã¶zelliklerinin sayÄ±sÄ±nÄ±*** ***`input_dim` parametresi*** ile belirtmeniz gerekir.\n",
        "  - Bir sinir aÄŸÄ± insan beynini taklit etmeye Ã§alÄ±ÅŸÄ±r. Burada, bu noktalarÄ± analiz etmeye baÅŸlamak iÃ§in 5 nÃ¶ron kullanmak istiyoruz.\n",
        "  - Her veri noktasÄ±, 5 nÃ¶ronla oluÅŸturulmuÅŸ ilk gizli katmandan geÃ§er:  \n",
        "    \\( layer_1 = \\begin{bmatrix} a_{1} \\\\ a_{2} \\\\ a_{3} \\\\ a_{4} \\\\ a_{5} \\end{bmatrix} \\)\n",
        "\n",
        "- <u>Ä°kinci Gizli Katman</u>:\n",
        "  - Bilginin, 4 nÃ¶ronlu ikinci bir gizli katmandan ***akmasÄ±nÄ±*** istersek ne olur? Bu tamamen mÃ¼mkÃ¼ndÃ¼r!\n",
        "  - Ä°kinci katmandaki bu 4 nÃ¶ron  \n",
        "    \\( layer_2 = \\begin{bmatrix} b_{1} \\\\ b_{2} \\\\ b_{3} \\\\ b_{4} \\end{bmatrix} \\),  \n",
        "    birinci katmandaki 5 nÃ¶ronun Ã§Ä±ktÄ±sÄ±nÄ± analiz eder.\n",
        "\n",
        "- <u>ÃœÃ§Ã¼ncÃ¼ Gizli Katman</u>:\n",
        "  - Bilginin 3 nÃ¶ronlu Ã¼Ã§Ã¼ncÃ¼ bir gizli katmandan **akmaya devam etmesini** istersek? Bu da tamamen mÃ¼mkÃ¼ndÃ¼r!\n",
        "  - Ä°kinci katmandaki her nÃ¶ronun Ã§Ä±ktÄ±sÄ±, 3 nÃ¶ronla oluÅŸturulmuÅŸ Ã¼Ã§Ã¼ncÃ¼ gizli katmandan geÃ§er:  \n",
        "    \\( layer_3 = \\begin{bmatrix} c_{1} \\\\ c_{2} \\\\ c_{3} \\end{bmatrix} \\)\n",
        "  - Bu 3 nÃ¶ron, \\( layer_2 \\) iÃ§indeki nÃ¶ronlarÄ±n Ã§Ä±ktÄ±sÄ±nÄ± analiz eder.\n",
        "\n",
        "- <u>Tahmin (Predictive) KatmanÄ±</u>:\n",
        "  - Ä°kili (binary) bir sÄ±nÄ±flandÄ±rma problemiyle uÄŸraÅŸÄ±yorsunuz.\n",
        "  - SÄ±nÄ±f A veya Bâ€™ye ait olma olasÄ±lÄ±ÄŸÄ±nÄ± tahmin etmek iÃ§in iki nÃ¶ron kullanÄ±labilir...\n",
        "  - Ancak â€œbaÅŸarÄ±â€ olasÄ±lÄ±ÄŸÄ±nÄ± tahmin eden tek bir nÃ¶ron yeterlidir.\n",
        "\n",
        "- <u>Aktivasyon fonksiyonlarÄ± hakkÄ±nda</u>:\n",
        "  - BasitliÄŸine raÄŸmen ***ReLU***, katmanlara doÄŸrusal olmayanlÄ±k (non-linearity) eklemek iÃ§in oldukÃ§a etkilidir.\n",
        "  - Tahmin katmanÄ± iÃ§in, sÄ±nÄ±flandÄ±rma problemlerinde kullanÄ±lacak en iyi aktivasyon fonksiyonu ***sigmoid*** fonksiyonudur.  \n",
        "    Bu konu Decision Science ve Machine Learning bÃ¶lÃ¼mlerinde daha Ã¶nce tartÄ±ÅŸÄ±lmÄ±ÅŸtÄ±.\n",
        "\n",
        "- <u>AÄŸÄ±n Sequential (SÄ±ralÄ±) yapÄ±sÄ± hakkÄ±nda</u>:\n",
        "  - **Sequential** bir model tanÄ±mlÄ±yor olmanÄ±zÄ±n bir sonucu vardÄ±r:  \n",
        "    her katman, bir Ã¶nceki katmanÄ±n Ã§Ä±ktÄ± boyutuna bakarak kendi girdi boyutunu otomatik olarak bilir.\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAPM1eHwqnJ7"
      },
      "source": [
        "â“ Bu kÃ¼Ã§Ã¼k Sinir AÄŸÄ±nda kaÃ§ parametre bulunmaktadÄ±r? â“"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "rBAoQUjGqnJ7",
        "outputId": "422e67d1-0d6f-4641-dd24-cb804a8d3cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\n",
        "58"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7TjyhY1qnJ7"
      },
      "source": [
        "<details>\n",
        "    <summary><i>Ä°pucu</i></summary>\n",
        "\n",
        "âœ… 58 parametreniz olmalÄ±dÄ±r.\n",
        "    \n",
        "âŒ DeÄŸilse, mimarinizi tekrar kontrol edin.    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMBItrofqnJ7"
      },
      "source": [
        "### (5) XOR Veri KÃ¼mesi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmtOIqVuqnJ7"
      },
      "source": [
        "â“ <u>XOR Veri KÃ¼mesi ile Oynamak</u> â“\n",
        "\n",
        "* Oyun AlanÄ±nda:\n",
        "- Veri kÃ¼mesini â€œXOR - Ã–zel Veyaâ€ olarak deÄŸiÅŸtirin.\n",
        "    - Ã‡ok kÃ¼Ã§Ã¼k bir **test kaybÄ±** olan iki gizli katmanlÄ± bir model tasarlamaya Ã§alÄ±ÅŸÄ±n.\n",
        "- Not: Katman baÅŸÄ±na nÃ¶ron sayÄ±sÄ±nÄ± kendiniz seÃ§ebilirsiniz.  \n",
        "        \n",
        "* Tensorflow/Keras ile kodlama:\n",
        "- Playground'da modelinizi oluÅŸturduktan sonra, aÅŸaÄŸÄ±da Tensorflow/Keras kÃ¼tÃ¼phanesi ile kodlayÄ±n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9qD3J39mqnJ7"
      },
      "outputs": [],
      "source": [
        "# XOR Veri Setine iyi uyarlanabilen Sinir AÄŸÄ±\n",
        "\n",
        "model.add(layers.Dense(1,activation='linear'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gIP77stqnJ7"
      },
      "source": [
        "### (6) Spiral Veri Seti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx1zEC7JqnJ7"
      },
      "source": [
        "â“ <u>Spiral Veri KÃ¼mesi ile Oynamak</u> â“\n",
        "\n",
        "* Oyun AlanÄ±nda:\n",
        "- Veri kÃ¼mesini â€œSpiralâ€ olarak deÄŸiÅŸtirin.\n",
        "    - Ã‡ok kÃ¼Ã§Ã¼k bir **test kaybÄ±** olan Ã¼Ã§ gizli katmanlÄ± bir model tasarlamaya Ã§alÄ±ÅŸÄ±n.\n",
        "- Not: Katman baÅŸÄ±na nÃ¶ron sayÄ±sÄ±nÄ± kendiniz seÃ§ebilirsiniz.  \n",
        "        \n",
        "* Tensorflow/Keras ile kodlama:\n",
        "- Playground'da modelinizi oluÅŸturduktan sonra, aÅŸaÄŸÄ±da Tensorflow/Keras kÃ¼tÃ¼phanesi ile kodlayÄ±n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iXJs6auBqnJ7",
        "outputId": "9478e9db-f9b6-4dcc-c660-602c62415d3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Sequential name=sequential_1, built=True>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "# Spiral Veri Setine iyi uyarlanabilen Sinir AÄŸÄ±\n",
        "from keras import Sequential, Input, layers\n",
        "\n",
        "model_spiral = Sequential()\n",
        "\n",
        "# GiriÅŸ katmanÄ±: Yine 2 Ã¶zellik (X1 ve X2)\n",
        "model_spiral.add(Input(shape=(2,)))\n",
        "\n",
        "# Gizli Katmanlar: Spiralin karmaÅŸÄ±klÄ±ÄŸÄ± iÃ§in nÃ¶ron sayÄ±larÄ±nÄ± artÄ±rdÄ±k\n",
        "model_spiral.add(layers.Dense(8, activation='relu'))  # 1. Gizli Katman (8 nÃ¶ron)\n",
        "model_spiral.add(layers.Dense(8, activation='relu'))  # 2. Gizli Katman (8 nÃ¶ron)\n",
        "model_spiral.add(layers.Dense(8, activation='relu'))  # 3. Gizli Katman (8 nÃ¶ron)\n",
        "\n",
        "# Ã‡Ä±ktÄ± KatmanÄ±: SÄ±nÄ±flandÄ±rma olduÄŸu iÃ§in 1 nÃ¶ron ve Sigmoid\n",
        "model_spiral.add(layers.Dense(1, activation='sigmoid'))\n",
        "model_spiral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpXsZ8lIqnJ8"
      },
      "source": [
        "### (7) Bir sinir aÄŸÄ± ne kadar derin olmalÄ±dÄ±r?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-XcCvb9qnJ8"
      },
      "source": [
        "ğŸ‘€ Spiral veri setini (Spiral Dataset) uyarlamak iÃ§in gereken parametre sayÄ±sÄ± ile XOR veri setini karÅŸÄ±laÅŸtÄ±rÄ±rsanÄ±z, ilkinin Ã§ok daha fazla aÄŸÄ±rlÄ±k (weight) gerektirdiÄŸini gÃ¶rÃ¼rsÃ¼nÃ¼z....\n",
        "\n",
        "ğŸ˜ƒ AslÄ±nda, modelleriniz yeterince derinse, teoride neredeyse her tÃ¼rlÃ¼ deseni (pattern) Ã¶ÄŸrenebilirsiniz...\n",
        "\n",
        "---\n",
        "\n",
        "<details>\n",
        "  <summary><i>Ã‡ok Derin (Very Deep) Sinir AÄŸlarÄ± oluÅŸturmalÄ± mÄ±yÄ±m?</i></summary>\n",
        "\n",
        "<u>Ã–rnekler:</u>\n",
        "\n",
        "* Bir insanÄ± dÃ¼ÅŸÃ¼nÃ¼n. Bu kiÅŸi Pythonâ€™da ne kadar Ã§ok zaman kod yazarsa, o kadar iyi olur!\n",
        "* Bir Ã¶ÄŸrenciyi dÃ¼ÅŸÃ¼nÃ¼n. Bu kiÅŸi ne kadar Ã§ok Ã§alÄ±ÅŸÄ±rsa, sÄ±navlarÄ± o kadar iyi geÃ§er. Ancak bazen Ã¶ÄŸrenciler bir konuya â€œfazlaâ€ odaklanÄ±p dersin genel resmini kaÃ§Ä±rabilirler....\n",
        "\n",
        "<u>Ã‡Ä±karÄ±mlar</u>\n",
        "\n",
        "ğŸ§  Derin Ã–ÄŸrenme (Deep Learning) modellerinde, katman sayÄ±sÄ± arttÄ±kÃ§a verideki Ã¶rÃ¼ntÃ¼leri Ã¶ÄŸrenmek iÃ§in daha fazla fÄ±rsat oluÅŸur.\n",
        "\n",
        "â—ï¸ AsÄ±l problem **overfitting (aÅŸÄ±rÄ± Ã¶ÄŸrenme)**â€™den kaÃ§Ä±nmaktÄ±r â—ï¸\n",
        "\n",
        "â˜ ï¸ EÄŸer veriye yeterince gÃ¼rÃ¼ltÃ¼ (noise) eklerseniz, modeliniz bu gÃ¼rÃ¼ltÃ¼yÃ¼ bile â€œfazla iyiâ€ Ã¶ÄŸrenmiÅŸ olabilir.\n",
        "\n",
        "ğŸ“† Bir sonraki ders olan **Deep Learning > Optimizers, Loss, & Fitting**, derin Ã¶ÄŸrenme modellerinde overfittingâ€™i Ã¶nlemek iÃ§in hangi teknikleri kullanabileceÄŸimizi anlamanÄ±za yardÄ±mcÄ± olacaktÄ±r.\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "<details>\n",
        "  <summary><i>Playgroundâ€™da overfittingâ€™e ait bir gÃ¶rsel</i></summary>\n",
        "\n",
        "<img src='https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/playground-overfitting.png' width=700 style='margin:auto'>\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqfHBW5eqnJ8"
      },
      "source": [
        "## Derin Ã–ÄŸrenmede Regresyon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWKerz-_qnJ8"
      },
      "source": [
        "<u>Derin Ã–ÄŸrenme kullanarak Regresyon GÃ¶revini tamamlamaya Ã§alÄ±ÅŸalÄ±m</u>\n",
        "\n",
        "\n",
        "Bu sefer, son katman artÄ±k ÅŸÃ¶yle gÃ¶rÃ¼nmeyecek:  \n",
        "```python\n",
        "model.add(layers.Dense(1, activation=â€˜sigmoidâ€™))\n",
        "```\n",
        "\n",
        "bunun yerine  :\n",
        "```python\n",
        "model.add(layers.Dense(1, activation=â€˜linearâ€™))\n",
        "```\n",
        "\n",
        "Bu, bu aÄŸÄ±n Ã§Ä±ktÄ±sÄ±nÄ±n artÄ±k $0$ ile $1$ (olasÄ±lÄ±k) arasÄ±nda deÄŸil, $ -\\infty$ ile $+ \\infty$ arasÄ±nda olduÄŸu anlamÄ±na gelir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGdidfB8qnJ8"
      },
      "source": [
        "â“ <u>Regresyon Veri KÃ¼mesi ile Oynamak</u> â“\n",
        "\n",
        "* Playground'da:\n",
        "- Veri kÃ¼mesini â€œRegresyonâ€ olarak deÄŸiÅŸtirin.\n",
        "    - **Test kaybÄ±** Ã§ok dÃ¼ÅŸÃ¼k olan bir model tasarlamaya Ã§alÄ±ÅŸÄ±n.\n",
        "        - Not: Katman sayÄ±sÄ±nÄ± ve katman baÅŸÄ±na nÃ¶ron sayÄ±sÄ±nÄ± kendiniz seÃ§ebilirsiniz.\n",
        "        \n",
        "* Tensorflow/Keras ile kodlama:\n",
        "    - Playground'da modelinizi oluÅŸturduktan sonra, aÅŸaÄŸÄ±da Tensorflow/Keras kÃ¼tÃ¼phanesi ile kodlayÄ±n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cpNZCwkXqnJ8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Regresyon Veri Setine iyi uyarlanabilen Sinir AÄŸÄ±\n",
        "\n",
        "from keras import Sequential, Input, layers\n",
        "\n",
        "model_regression=Sequential()\n",
        "#giriÅŸÅŸÅŸ katmanÄ±  2 Ã¶dellik x_1 or x_2\n",
        "model_regression.add(Input(shape=(2,)))\n",
        "\n",
        "#gizli katmanlar 2-3 katman\n",
        "model_regression.add(layers.Dense(10,activation='relu'))\n",
        "model_regression.add(layers.Dense(10,activation='relu'))\n",
        "\n",
        "#Ã§Ä±ktÄ± katmanÄ±\n",
        "\n",
        "model_regression.add(layers.Dense(1, activation='linear'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSB9ruFuqnJ8"
      },
      "source": [
        "ğŸ ArtÄ±k Tensorflow'un Keras ile aynÄ± ÅŸeyleri doÄŸrudan yapmaya hazÄ±rsÄ±nÄ±z!\n",
        "\n",
        "ğŸ’ª Bu, Sinir AÄŸlarÄ± / Derin Ã–ÄŸrenme Modelleri hakkÄ±nda bir IsÄ±nma egzersiziydi... (gerÃ§i, bu zorlukta aÄŸlarÄ±mÄ±z o kadar da â€œderinâ€ deÄŸildi).\n",
        "\n",
        "\n",
        "ğŸ’¾ Not defterinizi `git add/commit/push` yapmayÄ± unutmayÄ±n...\n",
        "\n",
        "ğŸš€ ... ve bir sonraki gÃ¶reve geÃ§in!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}